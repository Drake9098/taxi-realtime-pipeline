# ğŸš• Taxi Real-Time Pipeline (MLOps)

This is an **end-to-end MLOps project** implementing a real-time streaming pipeline for ML predictions on taxi data.

## ğŸ“‹ Project Status

ğŸš§ **Current Status:** Phase 1 Complete (Data Ingestion & Infrastructure)

- [x] Kafka Infrastructure Setup
- [x] Data Ingestion Producer (Python + Docker)
- [x] Model Training Service (In Progress)
- [ ] Inference API (Planned)

## ğŸ—ï¸ Repository Structure

```
taxi-realtime-pipeline/
â”‚
â”œâ”€â”€ producer/                  # ğŸ“¡ Kafka Producer Service
â”‚   â”œâ”€â”€ app.py                # Script to send data to Kafka
â”‚   â”œâ”€â”€ requirements.txt      # Python dependencies
â”‚   â””â”€â”€ Dockerfile            # Producer container
â”‚
â”œâ”€â”€ training/                  # ğŸ“ ML Training Service (ğŸš§ Work in Progress)
â”‚   â”œâ”€â”€ train.py              # Model training script
â”‚   â”œâ”€â”€ feature_engineering.py # Feature engineering pipeline
â”‚   â”œâ”€â”€ requirements.txt      # Training dependencies
â”‚   â””â”€â”€ Dockerfile            # Training container
â”‚
â”œâ”€â”€ inference/                 # ğŸš€ API Service (ğŸš§ Work in Progress)
â”‚   â”œâ”€â”€ main.py               # FastAPI app for model serving
â”‚   â”œâ”€â”€ requirements.txt      # Inference dependencies
â”‚   â””â”€â”€ Dockerfile            # API container
â”‚
â”œâ”€â”€ data/                      # ğŸ’¾ Local data (Excluded from Git)
â”‚   â””â”€â”€ .gitkeep              # Keeps folder in repo
â”‚
â”œâ”€â”€ docker-compose.yml         # ğŸ³ Complete orchestration
â”œâ”€â”€ .gitignore                 # ğŸ›¡ï¸ Protection from unwanted commits
â””â”€â”€ README.md                  # ğŸ“– Documentation
```

## ğŸ¯ Architecture Rationale

**Separation of Concerns:**
Each service (producer, training, inference) is completely isolated with separate dependencies, Dockerfile, and runtime. This enables independent deployments, horizontal scalability, and isolated testing.

**Reproducibility:**
Docker ensures consistent environments across different machines and stages (dev, staging, production).

## ğŸš€ Quick Start

### 1. Prerequisites

- **Docker** installed
- **Dataset**: Download one of the "Yellow Taxi Trip Records" (Parquet format) from the [official NYC TLC website](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)
  - Rename the file to `taxi_data.parquet`
  - Place it in the `data/` folder

### 2. Launch

```bash
# Start the entire infrastructure
docker-compose up -d --build
```

### 3. Access Services

- **Kafka UI**: [http://localhost:8080](http://localhost:8080) (Monitor data streaming)
- **MLflow UI**: [http://localhost:5000](http://localhost:5000) (Track experiments - Coming Soon)
- **Inference API**: [http://localhost:8000/docs](http://localhost:8000/docs) (Model predictions - Planned)

## ğŸ› ï¸ Tech Stack

- **Streaming:** Apache Kafka + Zookeeper
- **Infrastructure:** Docker + Docker Compose
- **Language:** Python 3.9
- **Libraries:** kafka-python, pandas, (Planned: scikit-learn, MLflow, FastAPI)

---
